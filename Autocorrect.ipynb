{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165a9369-9bbe-44c7-9ac5-be7059436aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/anaconda3/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "2023-12-28 18:00:27.619593: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-28 18:00:27.650609: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-28 18:00:27.650634: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-28 18:00:27.651394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-28 18:00:27.656189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "import torch.nn as nn\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tokenizers import Tokenizer\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import string\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bd70b6-e071-479d-8d50-31e8eefd0c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fd26cb-40dd-426c-8fd8-a2d439d47a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_trg_mask(length, device):\n",
    "    return torch.triu(\n",
    "        torch.ones(length, length, device=device) * float(\"-inf\"), diagonal=1\n",
    "    )\n",
    "\n",
    "def create_padding_mask(tensor, pad_idx):\n",
    "    padding_mask = (tensor == pad_idx).transpose(0, 1)\n",
    "\n",
    "    return padding_mask\n",
    "\n",
    "\n",
    "def masked_accuracy(y_true: torch.Tensor, y_pred: torch.Tensor, pad_idx):\n",
    "    mask = y_true != pad_idx\n",
    "    y_true = torch.masked_select(y_true, mask)\n",
    "    y_pred = torch.masked_select(y_pred, mask)\n",
    "    acc = (y_true == y_pred).double().mean()\n",
    "    return acc\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    #  https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 256):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    #  https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "\n",
    "class Seq2Seq(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        out_vocab_size,\n",
    "        pad_idx,\n",
    "        tokenizer,\n",
    "        channels=256,\n",
    "        dropout=0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pad_idx = pad_idx\n",
    "        self.dropout = dropout\n",
    "        self.out_vocab_size = out_vocab_size\n",
    "\n",
    "        self.embeddings = TokenEmbedding(\n",
    "            vocab_size=self.out_vocab_size, emb_size=channels\n",
    "        )\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model=channels, dropout=dropout)\n",
    "\n",
    "        self.transformer = torch.nn.Transformer(\n",
    "            d_model=channels,\n",
    "            nhead=4,\n",
    "            num_encoder_layers=6,\n",
    "            num_decoder_layers=6,\n",
    "            dim_feedforward=1024,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "\n",
    "        self.linear = Linear(channels, out_vocab_size)\n",
    "\n",
    "        self.do = nn.Dropout(p=self.dropout)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        init_range = 0.1\n",
    "        self.embeddings.weight.data.uniform_(-init_range, init_range)\n",
    "        self.linear.bias.data.zero_()\n",
    "        self.linear.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def encode_src(self, src):\n",
    "        #pdb.set_trace()\n",
    "        src = src.permute(1, 0)\n",
    "        src_pad_mask = create_padding_mask(src, self.pad_idx)\n",
    "        src = self.embeddings(src)\n",
    "        src = self.pos_encoder(src)\n",
    "        src = self.transformer.encoder(src, src_key_padding_mask=src_pad_mask)\n",
    "        #src = self.pos_encoder(src)\n",
    "        return src\n",
    "\n",
    "    def decode_trg(self, trg, memory):\n",
    "        trg = trg.permute(1, 0)\n",
    "        out_sequence_len, batch_size = trg.size(0), trg.size(1)\n",
    "        trg_pad_mask = create_padding_mask(trg, self.pad_idx)\n",
    "        trg = self.embeddings(trg)\n",
    "        trg = self.pos_encoder(trg)\n",
    "        trg_mask = gen_trg_mask(out_sequence_len, trg.device)\n",
    "        out = self.transformer.decoder(\n",
    "            tgt=trg, memory=memory, tgt_mask=trg_mask, tgt_key_padding_mask=trg_pad_mask\n",
    "        )\n",
    "        out = out.permute(1, 0, 2)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        #pdb.set_trace()\n",
    "        src, trg = x\n",
    "        src = self.encode_src(src)\n",
    "        out = self.decode_trg(trg=trg, memory=src)\n",
    "        return out\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"train\")\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.acc_sum = 0\n",
    "        self.acc_num = 0\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"valid\")\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        avg_acc = (self.acc_sum / self.acc_num).item()\n",
    "        self.log(\"val_avg_acc\", avg_acc)\n",
    "        print(\"Epoch, accuracy:\", self.current_epoch, round(avg_acc, 4))\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._step(batch, batch_idx, name=\"test\")\n",
    "\n",
    "    def ids_to_str(self, ids):        \n",
    "        is_end = np.nonzero(ids == tokenizer.token_to_id(\"[SEP]\"))[0]\n",
    "        if len(is_end) > 0:\n",
    "            end = is_end[0]\n",
    "            ids = ids[:end]     \n",
    "            \n",
    "        return self.tokenizer.decode(ids)\n",
    "    \n",
    " \n",
    "    def generate(self, input_str):\n",
    "        #pdb.set_trace()\n",
    "        input_tokens = torch.tensor(self.tokenizer.encode(input_str).ids, dtype=torch.long, device=self.device).unsqueeze(0)\n",
    "        src = self.encode_src(input_tokens)\n",
    "\n",
    "        outputs = torch.zeros((MAX_LEN, src.size(1)), dtype=torch.long, device=src.device)\n",
    "        outputs[0] = self.tokenizer.token_to_id(\"[CLS]\")\n",
    "\n",
    "        for i in range(1, MAX_LEN):\n",
    "            out = self.decode_trg(outputs[:i].T, memory=src)\n",
    "            _, next_token = torch.max(out, 2)\n",
    "            next_token = next_token[0,-1]\n",
    "            outputs[i] = next_token\n",
    "            if next_token == self.tokenizer.token_to_id(\"[SEP]\"):\n",
    "                break\n",
    "\n",
    "        output_ids = list(outputs.squeeze().cpu().numpy())\n",
    "        return self.tokenizer.decode(output_ids)\n",
    "\n",
    "    def _step(self, batch, batch_idx, name=\"train\"):\n",
    "        src, trg = batch\n",
    "        #pdb.set_trace()\n",
    "        trg_in, trg_out = trg[:, :-1], trg[:, 1:]\n",
    "        y_hat_orig = self((src, trg_in))\n",
    "        y_hat = y_hat_orig.view(-1, y_hat_orig.size(2))\n",
    "        y = trg_out.contiguous().view(-1)\n",
    "        \n",
    "        if batch_idx==0 and name==\"valid\":\n",
    "            tb_logger = None\n",
    "            for logger in self.trainer.loggers:\n",
    "                if isinstance(logger, TensorBoardLogger):\n",
    "                    tb_logger = logger.experiment\n",
    "                    break\n",
    "            \n",
    "            _, this_pred = torch.max(y_hat_orig, 2)\n",
    "            for i in range(16):                \n",
    "                text_truth = self.ids_to_str(trg_out[i].cpu().numpy())\n",
    "                text_corrupted = self.ids_to_str(src[i].cpu().numpy())\n",
    "                text_pred = self.ids_to_str(this_pred[i].cpu().numpy())\n",
    "                \n",
    "                output = \"Corrupted: {}<br>Corrected: {}<br>GrndTruth: {}\".format(text_corrupted, text_pred, text_truth)\n",
    "                tb_logger.add_text(f'Validation #{i}, target: {text_truth}', output, self.global_step)\n",
    "                \n",
    "        \n",
    "        loss = F.cross_entropy(y_hat, y, ignore_index=self.pad_idx)\n",
    "        _, predicted = torch.max(y_hat, 1)\n",
    "        acc = masked_accuracy(y, predicted, pad_idx=self.pad_idx)\n",
    "\n",
    "        #pdb.set_trace()\n",
    "        \n",
    "        self.log(f\"{name}_loss\", loss)\n",
    "        self.log(f\"{name}_acc\", acc)\n",
    "        \n",
    "        self.acc_sum += acc\n",
    "        self.acc_num += 1\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.parameters(), lr=3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78eabab2-e08d-4486-aa35-58079c9c366f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_perturbation_to_text(text):\n",
    "    #substitute e for c or c for e\n",
    "    #t for r\n",
    "    #m for ni, m for ui, n for ii, n for u, n for ii, u for ii, ium for mm, f for s\n",
    "    #cut out the middles of words, not whole words\n",
    "    \n",
    "    #There's a chance it'll be perfect\n",
    "    if np.random.uniform() < 0.1:\n",
    "        return text\n",
    "    \n",
    "    all_characters = string.ascii_lowercase + ' '\n",
    "    words = text.split()\n",
    "    if np.random.uniform() < 0.25 and len(words) > 1:\n",
    "        #Get rid of word\n",
    "        idx = np.random.randint(len(words))\n",
    "        words.pop(idx)                \n",
    "    \n",
    "    #Change word endings\n",
    "    for i in range(len(words)):\n",
    "        if words[i].endswith(\"ium\") and np.random.uniform() < 0.2:\n",
    "            words[i] = words[i][:-3] + \"ius\"\n",
    "        elif words[i].endswith(\"ius\") and np.random.uniform() < 0.2:\n",
    "            words[i] = words[i][:-3] + \"ium\"\n",
    "        elif words[i].endswith(\"us\") and np.random.uniform() < 0.2:\n",
    "            words[i] = words[i][:-2] + \"i\"     \n",
    "        elif words[i].endswith(\"nem\") and np.random.uniform() < 0.2:\n",
    "            words[i] = words[i][:-3] + \"nus\"\n",
    "    \n",
    "    curr_str = \" \".join(words)\n",
    "    new_str = \"\"\n",
    "    \n",
    "    for i in range(len(curr_str)):\n",
    "        if np.random.uniform() < 0.02:\n",
    "            new_str += np.random.choice(list(all_characters))\n",
    "        else:\n",
    "            new_str += curr_str[i]\n",
    "            \n",
    "        #There's a chance for a new character to pop up\n",
    "        if np.random.uniform() < 0.02:\n",
    "            new_str += np.random.choice(list(all_characters))\n",
    "            \n",
    "    return new_str\n",
    "\n",
    "def generate_batch(data_batch, pad_idx):\n",
    "    src, trg = [], []\n",
    "    for (src_item, trg_item) in data_batch:\n",
    "        src.append(src_item)\n",
    "        trg.append(trg_item)\n",
    "    src = pad_sequence(src, padding_value=pad_idx, batch_first=True)\n",
    "    trg = pad_sequence(trg, padding_value=pad_idx, batch_first=True)\n",
    "    return src, trg\n",
    "\n",
    "\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, hf_tokenizer):\n",
    "        self.samples = samples\n",
    "        self.n_samples = len(self.samples)\n",
    "        self.hf_tokenizer = hf_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.samples[idx]\n",
    "        perturbed_text = apply_perturbation_to_text(text)\n",
    "\n",
    "        x = self.hf_tokenizer.encode(perturbed_text).ids\n",
    "        y = self.hf_tokenizer.encode(text).ids\n",
    "        #print(text, len(x), len(y))\n",
    "        #assert(len(x) < MAX_LEN)\n",
    "        #assert(len(y) < MAX_LEN)\n",
    "        x = torch.tensor(x, dtype=torch.long)\n",
    "        y = torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7191847b-a420-45a7-85c0-fb289ca0bb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text):\n",
    "    words = text.split()\n",
    "    i = 0\n",
    "    lines = []\n",
    "    while True:\n",
    "        num_words = np.random.randint(2, 30)\n",
    "        lines.append(\" \".join(words[i:i+num_words]))\n",
    "        i += num_words\n",
    "        if i >= len(words):\n",
    "            break\n",
    "            \n",
    "    return lines\n",
    "\n",
    "lines = []\n",
    "weights = []\n",
    "\n",
    "for filename in [\"decretum.txt\", \"corpus_thomisticum.txt\", \"misc_medieval.txt\"]:\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "        new_lines = split_text(data)\n",
    "        lines += new_lines\n",
    "        weights += len(new_lines) * [1./len(new_lines)]\n",
    "\n",
    "with open(\"cases_training_lines.txt\") as f:\n",
    "    new_lines = f.readlines()\n",
    "    lines += new_lines\n",
    "    weights += len(new_lines) * [1./len(new_lines)]\n",
    "    \n",
    "lines = np.array(lines)\n",
    "weights = np.array(weights)\n",
    "    \n",
    "tokenizer = Tokenizer.from_file(\"latin_tokenizer.json\")    \n",
    "train_inds, val_inds = train_test_split(np.arange(len(lines)), test_size=0.1, random_state=1337)\n",
    "\n",
    "train_data = Dataset(samples=lines[train_inds], hf_tokenizer=tokenizer)\n",
    "val_data = Dataset(samples=lines[val_inds], hf_tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8acd4d7-18e4-44c7-990d-512e8d18927f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_data) 705769\n",
      "len(val_data) 78419\n"
     ]
    }
   ],
   "source": [
    "def generate_batch(data_batch, pad_idx):\n",
    "    src, trg = [], []\n",
    "    for (src_item, trg_item) in data_batch:\n",
    "        src.append(src_item)\n",
    "        trg.append(trg_item)\n",
    "    src = pad_sequence(src, padding_value=pad_idx, batch_first=True)\n",
    "    trg = pad_sequence(trg, padding_value=pad_idx, batch_first=True)\n",
    "    return src, trg\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=WeightedRandomSampler(weights[train_inds], num_samples=len(train_inds), replacement=True), \n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    collate_fn=partial(generate_batch, pad_idx=tokenizer.token_to_id(\"[PAD]\")),\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_data,\n",
    "    sampler=WeightedRandomSampler(weights[val_inds], num_samples=len(val_inds), replacement=True), \n",
    "    batch_size=128,\n",
    "    num_workers=4,\n",
    "    collate_fn=partial(generate_batch, pad_idx=tokenizer.token_to_id(\"[PAD]\")),\n",
    ")\n",
    "\n",
    "print(\"len(train_data)\", len(train_data))\n",
    "print(\"len(val_data)\", len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cd4a8f-40ef-40ac-845a-28235f20053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/stanley/anaconda3/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /home/stanley/work/latin_documents exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type               | Params\n",
      "---------------------------------------------------\n",
      "0 | embeddings  | TokenEmbedding     | 1.3 M \n",
      "1 | pos_encoder | PositionalEncoding | 0     \n",
      "2 | transformer | Transformer        | 11.1 M\n",
      "3 | linear      | Linear             | 1.3 M \n",
      "4 | do          | Dropout            | 0     \n",
      "---------------------------------------------------\n",
      "13.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "13.6 M    Total params\n",
      "54.501    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch, accuracy: 0 0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/anaconda3/lib/python3.9/site-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc3a576aeb543e5932a88c6647d9838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stanley/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "model = Seq2Seq.load_from_checkpoint(\"checker-v20.ckpt\", out_vocab_size=tokenizer.get_vocab_size(),\n",
    "    pad_idx=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    tokenizer=tokenizer,\n",
    "    dropout=0.1)\n",
    "\n",
    "# model = Seq2Seq(\n",
    "#     out_vocab_size=tokenizer.get_vocab_size(),\n",
    "#     pad_idx=tokenizer.token_to_id(\"[PAD]\"),\n",
    "#     tokenizer=tokenizer,\n",
    "#     dropout=0.1\n",
    "# )\n",
    "#model.load_state_dict(torch.load(\"autocorrect.pt\"))\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"valid_acc\", mode=\"max\", dirpath=\"./\", filename=\"checker\"\n",
    ")\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "        save_dir=\"./\",\n",
    "        name=\"autocorrect_logs\",\n",
    "    )\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=2000,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a0d46-d7fd-4867-9081-e0e408fe5a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"autocorrect_special_tokens.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d33fe59-3a85-40e5-a549-0ff3d4c953c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Test the model we just trained\n",
    "\n",
    "# model = Seq2Seq(\n",
    "#     out_vocab_size=tokenizer.get_vocab_size(),\n",
    "#     pad_idx=tokenizer.token_to_id(\"[PAD]\"),\n",
    "#     tokenizer=tokenizer,\n",
    "#     dropout=0.1\n",
    "# )\n",
    "# model.load_state_dict(torch.load(\"autocorrect_special_tokens.pt\"))\n",
    "# #model.generate(\"dignitatm divinae Scripturae pertinet, ut sub una littera multos sensus contineat, ut sic et diversis intellectibi rhominum conveniat\")\n",
    "\n",
    "# input_str = \"probatorem et clericum conuictum et eunt ab eius duas vaccas et sex bonuculos pro xxx. S.. vnde idem Galfridus\"\n",
    "# input_tokens = torch.tensor(model.tokenizer.encode(input_str).ids, dtype=torch.long).unsqueeze(0)\n",
    "# src = model.encode_src(input_tokens)\n",
    "\n",
    "# outputs = torch.zeros((MAX_LEN, src.size(1)), dtype=torch.long, device=src.device)\n",
    "# outputs[0] = model.tokenizer.token_to_id(\"[CLS]\")\n",
    "\n",
    "# for i in range(1, MAX_LEN):\n",
    "#     out = model.decode_trg(outputs[:i].T, memory=src)\n",
    "#     _, next_token = torch.max(out, 2)\n",
    "#     next_token = next_token[0,-1]\n",
    "#     outputs[i] = next_token\n",
    "#     if next_token == model.tokenizer.token_to_id(\"[SEP]\"):\n",
    "#         break\n",
    "        \n",
    "# output_ids = list(outputs.squeeze().numpy())\n",
    "# print(model.tokenizer.decode(output_ids))\n",
    "# print(model.tokenizer.decode(output_ids[:input_tokens.size(1)-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82a1defa-f311-4c40-9a60-701c520f81ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'iure participant, nonne magis nos? sed ea non sumus usi hac potestate, sed omnia tolleramus, ne quod inpentum demus evangelio Christi.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test the model\n",
    "model = Seq2Seq.load_from_checkpoint(\"checker-v20.ckpt\", out_vocab_size=tokenizer.get_vocab_size(),\n",
    "    pad_idx=tokenizer.token_to_id(\"[PAD]\"),\n",
    "    tokenizer=tokenizer,\n",
    "    dropout=0.1)\n",
    "model.load_state_dict(torch.load(\"autocorrect_special_tokens.pt\"))\n",
    "model.to(\"cuda:0\")\n",
    "#model.generate(\"Sidure fecit capitus dominus feodi mediatur et inmedatur essendi hic etc. sei etc. Et iuratores veniunt qui dicunt super sacr in\")\n",
    "\n",
    "model.generate(\"iurlepartcipant, nonne magis nos? sedea non sumus usi hac potestate, sed omnia tolleramus, ne quod inpedntum demus evangelio Christi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc3b3d-e3bf-4341-a7ed-61472b5a6d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
