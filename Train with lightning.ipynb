{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03873bc-01a2-40c6-859b-89ef96ca1294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as L\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import torch\n",
    "import pdb\n",
    "import numpy as np\n",
    "from torchmetrics.text import CharErrorRate, WordErrorRate\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "from torch.utils.data import Dataset\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "import os.path\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e70bdb0b-5119-4ba2-8887-71cec75d1ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<md5 _hashlib.HASH object @ 0x7f6f65a3f090>\n"
     ]
    }
   ],
   "source": [
    "from hashlib import md5\n",
    "string = \"test\"\n",
    "print(md5(string.encode()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90726e1c-fc59-445c-a9cd-9fb87c76e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "all_chars = \" ',-.:;ABCDEFGHIJKLMNOPQRSTUVWXabcdefghijklmnopqrstuvwxyz°¶–’\"\n",
    "print(len(all_chars))\n",
    "char_to_num = {}\n",
    "num_to_char = {}\n",
    "for i in range(len(all_chars)):\n",
    "    num_to_char[i+1] = all_chars[i]\n",
    "    char_to_num[all_chars[i]] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f0639e-072c-4e91-8ea9-aa503aae2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineImageDataset(Dataset):\n",
    "    def classify(self, line_im_filename):\n",
    "        str_hash = hashlib.md5(line_im_filename.encode()).hexdigest()\n",
    "        hash_num = int(str_hash[:8], 16) % 100 #\"random\" num between 0 and 99\n",
    "        if hash_num < 90: return \"train\"\n",
    "        else: return \"val\"\n",
    "    \n",
    "    def __init__(self, dirname, char_to_num, num_to_char, data_type, transform=None):\n",
    "        self.transform = transform       \n",
    "        self.char_to_num = char_to_num\n",
    "        self.num_to_char = num_to_char\n",
    "        self.data_type = data_type\n",
    "        self.line_images = []\n",
    "        self.line_image_filenames = []\n",
    "        self.labels = []\n",
    "        self.num_labels = []\n",
    "        \n",
    "        #Iterate over all lines of all XML files\n",
    "        ns = {'ns': 'http://schema.primaresearch.org/PAGE/gts/pagecontent/2013-07-15'}\n",
    "        ET.register_namespace('', ns['ns'])\n",
    "\n",
    "        #print(dirname)\n",
    "        #print(glob.glob(\"./data/*.xml\"))\n",
    "        for filename in sorted(glob.glob(dirname + \"/*.xml\")):\n",
    "            #print(filename)\n",
    "            tree = ET.parse(filename)\n",
    "            root = tree.getroot()\n",
    "\n",
    "            image_filename = root.find('ns:Page', ns).get('imageFilename')\n",
    "\n",
    "            #First iteration: calculate average line spacing\n",
    "            for text_region in root.findall('.//ns:TextRegion', ns):\n",
    "                for lineno, text_line in enumerate(text_region.findall('.//ns:TextLine', ns)):                    \n",
    "                    line_im_filename = dirname + \"/line_{}_{}\".format(lineno, image_filename)\n",
    "                    line_im_filename, _ = os.path.splitext(line_im_filename)\n",
    "                    line_im_filename += \".png\"\n",
    "                    if self.classify(line_im_filename) != data_type:\n",
    "                        continue\n",
    "                        \n",
    "                    self.line_image_filenames.append(line_im_filename)\n",
    "                    #self.line_images.append(read_image(line_im_filename, ImageReadMode.GRAY))   \n",
    "                    self.line_images.append(torch.tensor(np.load(line_im_filename.replace(\".png\", \".npy\")), dtype=torch.float32).unsqueeze(0))\n",
    "                    \n",
    "                    text = text_line.find('.//ns:TextEquiv', ns).find('.//ns:Unicode', ns).text\n",
    "                    self.labels.append(text.strip())\n",
    "                    self.num_labels.append(torch.tensor([self.char_to_num[c] for c in text]))\n",
    "                    if self.classify(line_im_filename) == \"val\":\n",
    "                        print(text)\n",
    "                                        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):                \n",
    "        image = self.line_images[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            #median = torch.median(image)\n",
    "            image = self.transform(image)\n",
    "            #image[image == -1] = torch.median(image)\n",
    "       \n",
    "        return {\"image\": image, \"target\": self.num_labels[idx], \"text\": self.labels[idx]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70232bef-28d4-4c52-ae0d-4d734e00619d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elemosina pertinens ad ecclesiam de Duddebir unde Willelmus de Ros est persona an laicum feodum Roberti de Furches \n",
      "mesuagio et duabus acris terre cum pertinenciis in Stokes die quo obilt etc. et si etc. Unde Adam de Stok unum mesuagium \n",
      "alius ipsam inde inplacitaret teneretur ei warantizare. Et predictus Colemannus le Blund non potest hoc \n",
      "dicunt enim quod idem Colemannus per longum tempus ante mortem suam tenementa illa dedit et concessit cuidam Colemanno \n",
      "predicta communa nisi ex gracia et pro suo dando et aliquando faciendo sectam ad molendinum predicti Thome de Brochton. Et ideo consideratum \n",
      "dicunt quod, si aliqua disseisina ei inde facta fuerit, facta fuit per predictum Galfridum patrem predicti Galfridi de Ledewyk et non per ipsum Galfridum \n",
      "Et perquirat sibi per aliud breve si voluerit. Pardonatur misericordia quia infra etatem.\n",
      "Et Willelmus et Iohannes veniunt et nichil dicunt quare assisa remaneat.\n",
      "super sacramentum suum hoc idem testantur. Et ideo consideratum est quod predictus Michaelis inde sine die. et Willmus filius Thome nichil \n",
      "¶ Ass. ven. rec. si Rogerus filius Celestrie et Nicholaus Tubbe injuste etc. disseisiverunt Willemum le Flemmeng de commu\n",
      "et Nicholaus frussire fecerunt et in culturam redigere predictam brueram quo minus in ea communicare possit \n",
      "Juratores dicunt quod predicti Rogerus et Nicholaus disseisiverunt predictum Willelmum de predicta communa pasture injuste etc. sicut breve dicit. \n",
      "Ideo consideratum est quod predictus Willelmus recuperet seisinam suam per visum recognitorum et Rogerus et Nicholaus in misericordia.\n",
      "etc. ad faciendum recognicionem magne assise summonite inter Radulfum le Butiller et Matillidem uxorem ejus petentes et Willelmum del Ake tenentem de septem \n",
      "de terris etc.\n",
      "domini Regis nunc feofaverat ipsum de predicto manerio cum omnibus libertatibus et liberis consuetudinibus ad manerium illud \n",
      "fuit in seisina de eadem libertate tanquam ad predictum manerium pertinente, et post mortem ipsius Hugonis quidam Willelmus \n",
      "in escambium pro quodam alio manerio quod ei dedit tenendum de domino Rege in capite cum omnibus libertatibus et liberis \n",
      "Et Thomas defendit vim et injuriam quando etc. et bene defendit quod ipse predicto die ad predictam prisonam non venit \n",
      "Et Willelmus de Hempton' bene cognoscit quod predictus Henricus filius Willelmi aliquo tempore fecerat predicto \n",
      "tinuerunt per duos dies quousque deliberatus fuit per breve domini regis. Et cum ipsum abire permiserunt predictum \n",
      "et modo non habet. Ideo in misericordia.\n",
      "Et Iohannes de Thorp venit et defendit is suum quando etc. et dicit quod predictus Iohannes de la Mare nichil juris clamare \n",
      "proxima post festum Sancti Mathei anno regni regis nunc secundo allocutus fuit de morte predicta et ibidem tanquam \n",
      "Et postea coram Henrico Lincolniensi episcopo se purgauit et profert inde litteras ipsius episcopi patentes in hec verba\n",
      "pagine fideliter comendentur, vniuersitati vestre notum facimus per presentes quod Thomas Lambard clericus super \n",
      "in foro ecclesiastico secundum canonicas sanctiones no modo vel alio per iusticiarios domini regis liberatus, post plures \n",
      "clamaciones in locis hui negocio oportunis solempniter et publice promulgatas cum nullus esset qui per viam \n",
      "Thomas le Corour de Knottyngg captus per appellum Galfridi de Wodhulle probatoris et clerici conuicti \n",
      "probatorem et clericum conuictum et emit ab eis duas vaccas et sex bouiculos pro .xxx. solidis vnde idem Galfridus \n",
      "et eciam num bouiculum Henrici Pentyn precii .v. solidorum in eodem parco inuentum felonice furatus fuit -- et similiter \n",
      "vnam dimidiam acram\n",
      "habit terram in eadem villa et plura catalla que regi etc. Ideo preceptum est vicecomiti Bedford quod per sacramentum etc. diligenter inquirat \n",
      "ecclesiam de Assheby Maris et custoditus in eadem per villatam de Assheby quousque idem Willelmus noctanter felonice euasit \n",
      "Elias de Assheburn capitalis dominus terre predicte prout iuratores testantur et fecit finem cum domino rege pro ingressu habendo etc. per .xl. denarios, \n",
      "Matillis que fuit vxor Roberti de Hastyng petit versus Iohannem filium Roberti de Hastyng terciam partem quadraginta \n",
      "Et lohannes venit et dicit quod predicta Matillis non debet inde dotem habere, quia dicit quod ipsa post mortem predicti Roberti \n",
      "Et Matillis dicit quod predictus Iohannes ad aliquam verificacionem patrie non est admittendus in hoc casu maxime \n",
      "de predicto redditu quadraginta solidorum uersus se ipsum redditum vt tenentem in socagio et uersus predictum \n",
      "in predictis villis versus prefatum Iohannem. Et idem Iohannes in misericordia.  Et predicta Matillis petit dampna sibi audiu\n",
      "de vno mesuagio et sex acris terre cum pertinenciis etc.\n",
      "Radulfus Basset de Welledon chiualer et lohanna vxor eius in misericordia pro pluribus defaltis.\n",
      "presentare idoneam personam ad ecclesiam de Asshele que vacat et ad suam spectat donacionem etc. Et nde idem abbas \n",
      "candem ecclesiam presentauit quemdam Willelmum Peuerel clericum suum qui ad presentacionem suam fuit admissus et insti\n",
      "domini Edwardi regis aui domini regis nunc. Et dicit quod de predicta Agnete descendit jus etc. cuidam Radulfo vt filio et heredi et de \n",
      "ipso Radulfo quia obiit sine herede de se descendit is etc. cuidam Ricardo de Pydyngton vt consanguineo et heredi\n",
      "ad presentacionem suam fuit admissus et institutus tempore pacis tempore domini Edwardi regis patris domini regis nunc. Et dicit \n",
      "dicit quod predicti Rogers et Margeria iniuste se queruntur in hac parte, quia dicit quod quidam Iohannes pater ipsius \n",
      "ent inde seisinam sum per visum recognitorum et dampna sua que taxantur per eosdem ad viginti solidos. \n",
      "falso clamore versus predictum Willelmum etc. Postea in curia hic venit predictus Rogers de Whyteby et cognouit quod satisfactum est \n",
      "Iohannes Braynet Thomas del Marche per vicecomitem ducti. Et iuratores in nullo malecredunt ipsum lohannem Brayn de morte predicta\n",
      " et malo ponit se super patriam. Et juratores villatede Brackele dicunt super sacramentum suum quod predictus Thomas \n",
      "nunquam in custodia predicti Iohannis deuenit. Et hoc paratus est verificare prout curia. etc. Ideo datus est ei dies, die Lunae proxima post festum\n",
      "die Lune prx’ post festum sti Mathie apoti anno regni regis E. aui regis nunc . xx. Et predictus Wills \n",
      "auus etc mandauit bre suu vic et coron in hec verba. --- Edwardus dei gra rex Anglie dus Hibern et dux\n",
      "lefactores et pacis nre perturbatores interfecti vt dicitur cepistis in manu nram ac si bona et cat predicta per feloniam\n",
      "et catalla illa prefate milicente sine dilacione deliberari facis per securitate predam. Et heas ibi hoc bre. T.\n",
      "de Esseby, Thom ad Crucem de Bucketon, Willi Prest de Briclesworth et Phi le Clerk de Wolaston ad \n",
      "Postea iurati testantur quod predictus Willelmus captus fuit et liberatus in custodia, Iohannis de Wyleby tunc vicecomitis Northampton. Ideo .\n",
      "voluisset appellum etc. qui dixit, quod clericus fuit, et non potuit sine ordinario respondere etc. per quod tanquam clericus\n",
      "Iohannes de Carleton captus fuit pro morte Radulphi Parleben apud Multon felonice interfecti et liberatus in custodia\n",
      "{'image': tensor([[[-0.9805, -0.9805, -0.9380,  ..., -0.5473, -0.4870, -0.4870],\n",
      "         [-0.9805, -0.9805, -0.9380,  ..., -0.5473, -0.4870, -0.4870],\n",
      "         [-0.9122, -0.9122, -0.8779,  ..., -0.5867, -0.5173, -0.5173],\n",
      "         ...,\n",
      "         [-0.7896, -0.7896, -0.7226,  ..., -0.9765, -0.9475, -0.9475],\n",
      "         [-0.8442, -0.8442, -0.7608,  ..., -0.9775, -0.9577, -0.9577],\n",
      "         [-0.8442, -0.8442, -0.7608,  ..., -0.9775, -0.9577, -0.9577]]]), 'target': tensor([36, 43, 36, 44, 46, 50, 40, 45, 32,  1, 47, 36, 49, 51, 40, 45, 36, 45,\n",
      "        50,  1, 32, 35,  1, 36, 34, 34, 43, 36, 50, 40, 32, 44,  1, 35, 36,  1,\n",
      "        11, 52, 35, 35, 36, 33, 40, 49,  1, 52, 45, 35, 36,  1, 30, 40, 43, 43,\n",
      "        36, 43, 44, 52, 50,  1, 35, 36,  1, 25, 46, 50,  1, 36, 50, 51,  1, 47,\n",
      "        36, 49, 50, 46, 45, 32,  1, 32, 45,  1, 43, 32, 40, 34, 52, 44,  1, 37,\n",
      "        36, 46, 35, 52, 44,  1, 25, 46, 33, 36, 49, 51, 40,  1, 35, 36,  1, 13,\n",
      "        52, 49, 34, 39, 36, 50,  1]), 'text': 'elemosina pertinens ad ecclesiam de Duddebir unde Willelmus de Ros est persona an laicum feodum Roberti de Furches'}\n"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.ToPILImage(),\n",
    "       transforms.ColorJitter(0.5, 0.5, 0.5, 0.5),\n",
    "       transforms.RandomAffine(0.7, translate=(0.01, 0.02), scale=(0.98, 1.02)),\n",
    "       transforms.RandomChoice([\n",
    "           transforms.RandomAdjustSharpness(2, p=0.5),\n",
    "            transforms.GaussianBlur(21, (1,6))\n",
    "        ]),\n",
    "        #transforms.RandomEqualize(p=1),\n",
    "        #transforms.ToTensor(),        \n",
    "        transforms.Normalize(0.15, 0.38)\n",
    "    ])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.ToPILImage(),\n",
    "        #transforms.RandomEqualize(p=1),\n",
    "        #transforms.ToTensor(),        \n",
    "        transforms.Normalize(0.15, 0.38)\n",
    "    ])\n",
    "\n",
    "train_dataset = LineImageDataset(\"data/\", char_to_num, num_to_char, data_type=\"train\", transform=train_transform)\n",
    "val_dataset = LineImageDataset(\"data/\", char_to_num, num_to_char, data_type=\"val\", transform=val_transform)\n",
    "print(val_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d535b-b0e8-47bb-839d-b6bb8a96e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(torch.tensor(np.load(\"data/line_0_0001_JUST1-734m5d.npy\")))\n",
    "idx = 40\n",
    "print(val_dataset[idx][\"image\"][0].mean(), val_dataset[idx][\"image\"][0].std())\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.imshow(train_dataset[20][\"image\"][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a765fa35-3984-4291-848d-2dc3a6f3f8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyNN(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.features = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, (4,16), padding=(1,7)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(0.1),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            \n",
    "#             nn.Conv2d(32, 32, (4,16), padding=(1,7)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(0.1),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            \n",
    "#             nn.Conv2d(32, 64, (3,8), padding=(1,3)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(0.1),\n",
    "#             nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            \n",
    "#             nn.Conv2d(64, 64, (3,8), padding=(1,3)),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Dropout2d(0.1)\n",
    "#         )\n",
    "        \n",
    "#         self.lstms = nn.ModuleList([\n",
    "#             nn.LSTM(960, 256, bidirectional=True, batch_first=True),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.LSTM(512, 256, bidirectional=True, batch_first=True),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.LSTM(512, 256, bidirectional=True, batch_first=True),\n",
    "#             nn.Dropout(0.3),\n",
    "#         ])\n",
    "#         self.lin = nn.Linear(512, 62)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.features(x)\n",
    "#         x = x.contiguous().view(-1, x.shape[1] * x.shape[2], x.shape[3]).transpose(1,2)\n",
    "#         #x = x.contiguous().view(x.shape[0], x.shape[3], x.shape[1] * x.shape[2])\n",
    "        \n",
    "#         for layer in self.lstms:\n",
    "#             if isinstance(layer, nn.LSTM):\n",
    "#                 x, _ = layer(x)\n",
    "#             else:\n",
    "#                 x = layer(x)      \n",
    "#         x = self.lin(x)\n",
    "#         x = nn.functional.log_softmax(x, dim=2)\n",
    "#         return x.transpose(1,2)\n",
    "\n",
    "# net = MyNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae74967-2d80-4683-93b0-8cf0c5cb700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, (4,16), padding=(1,7)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),            \n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Conv2d(32, 32, (4,16), padding=(1,7)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Conv2d(32, 64, (3,8), padding=(1,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)),\n",
    "            nn.Conv2d(64, 64, (3,8), padding=(1,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        \n",
    "        self.lstms = nn.ModuleList([\n",
    "            nn.LSTM(960, 256, bidirectional=True, batch_first=True),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.LSTM(512, 256, bidirectional=True, batch_first=True),\n",
    "            nn.Dropout(0.3),\n",
    "            #nn.BatchNorm1d(256),\n",
    "            nn.LSTM(512, 256, bidirectional=True, batch_first=True),\n",
    "            nn.Dropout(0.3),\n",
    "        ])\n",
    "        self.lin = nn.Linear(512, 62)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.contiguous().view(-1, x.shape[1] * x.shape[2], x.shape[3]).transpose(1,2)\n",
    "        #x = x.contiguous().view(x.shape[0], x.shape[3], x.shape[1] * x.shape[2])\n",
    "        \n",
    "        for layer in self.lstms:\n",
    "            if isinstance(layer, nn.LSTM):\n",
    "                x, _ = layer(x)\n",
    "            else:\n",
    "                x = layer(x)      \n",
    "        x = self.lin(x)\n",
    "        x = nn.functional.log_softmax(x, dim=2)\n",
    "        return x.transpose(1,2)\n",
    "\n",
    "net = MyNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b10444c-ae13-4027-9ac1-0370db400a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\")\n",
    "\n",
    "class LatinTranscriber(L.LightningModule):\n",
    "    def __init__(self, net, codec_l2c):\n",
    "        super().__init__()\n",
    "        self.codec_l2c = codec_l2c\n",
    "        self.cer_calc = CharErrorRate()\n",
    "        self.wer_calc = WordErrorRate()\n",
    "        self.train_cer_calc = CharErrorRate()\n",
    "        self.train_wer_calc = WordErrorRate()\n",
    "        self.net = net\n",
    "                \n",
    "    def get_loss(self, batch, batch_idx):\n",
    "        #input, _, target = batch\n",
    "        \n",
    "        target = batch[\"target\"]\n",
    "        target_length = batch[\"target\"].shape[1]\n",
    "       \n",
    "        #self.net = self.net.to(device)\n",
    "        input = batch[\"image\"]#.to(device)\n",
    "        \n",
    "        #output, _ = self.net(input)\n",
    "        output = self.net(input)\n",
    "        #print(\"Output shape\", output.shape)\n",
    "        # height should be 1 by now\n",
    "        #if output.size(2) != 1:\n",
    "        #    raise ValueError('Expected dimension 3 to be 1, actual {}'.format(output.size(2)))\n",
    "        #output = output.squeeze(2)\n",
    "        \n",
    "        output_length = output.shape[-1]\n",
    "        \n",
    "        loss_func = nn.CTCLoss(reduction='sum', zero_infinity=True)\n",
    "        loss = loss_func(output.permute(2,0,1), target, (output_length,), (target_length,))\n",
    "        return loss, output\n",
    "    \n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_cer_calc.reset()\n",
    "        self.train_wer_calc.reset()\n",
    "        \n",
    "        \n",
    "    def _get_current_lr(self):\n",
    "        for param_group in self.trainer.optimizers[0].param_groups:\n",
    "            return param_group['lr']\n",
    "        \n",
    "    def on_train_epoch_end(self):\n",
    "        char_accuracy = 1 - self.train_cer_calc.compute()\n",
    "        word_accuracy = 1 - self.train_wer_calc.compute()\n",
    "        lr = self._get_current_lr()\n",
    "        \n",
    "        self.log(\"train_char_acc\", char_accuracy)\n",
    "        self.log(\"train_word_acc\", word_accuracy)\n",
    "        self.log('lr-Adam', lr)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        assert self.net.training\n",
    "        loss, output = self.get_loss(batch, batch_idx)\n",
    "        prediction, truth = self.get_prediction_and_truth(output, batch[\"target\"])\n",
    "        self.train_cer_calc.update(truth, prediction)\n",
    "        self.train_wer_calc.update(truth, prediction)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def get_prediction_and_truth(self, output, target):\n",
    "        target = torch.squeeze(target).cpu().numpy()\n",
    "        #truth = ''.join([self.codec_l2c[(target[i].item(),)] for i in range(len(target))])        \n",
    "        truth = ''.join([self.codec_l2c[target[i].item()] for i in range(len(target))])  \n",
    "        labels = torch.argmax(torch.squeeze(output), axis=0).cpu().numpy()\n",
    "        prediction = \"\"\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            if label != 0 and (i==0 or label != labels[i-1]):\n",
    "                #prediction += self.codec_l2c[(label,)]\n",
    "                prediction += self.codec_l2c[label]\n",
    "                \n",
    "        return prediction, truth\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        assert not self.net.training\n",
    "        assert batch[\"target\"].shape[0] == 1\n",
    "        loss, output = self.get_loss(batch, batch_idx)\n",
    "        prediction, truth = self.get_prediction_and_truth(output, batch[\"target\"])\n",
    "        self.cer_calc.update(truth, prediction)\n",
    "        self.wer_calc.update(truth, prediction)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            print(\"batch 0\", truth)\n",
    "        # Get tensorboard logger\n",
    "        if batch_idx < 16:\n",
    "            tb_logger = None\n",
    "            for logger in self.trainer.loggers:\n",
    "                if isinstance(logger, pl_loggers.TensorBoardLogger):\n",
    "                    tb_logger = logger.experiment\n",
    "                    break\n",
    "\n",
    "            tb_logger.add_image(f'Validation #{batch_idx}, target: {truth}', batch['image'][0], self.global_step, dataformats=\"CHW\")\n",
    "            tb_logger.add_text(f'Validation #{batch_idx}, target: {truth}', prediction, self.global_step)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_epoch_start(self):\n",
    "        self.cer_calc.reset()\n",
    "        self.wer_calc.reset()\n",
    "        \n",
    "    def on_validation_epoch_end(self):\n",
    "        char_accuracy = 1 - self.cer_calc.compute()\n",
    "        word_accuracy = 1 - self.wer_calc.compute()\n",
    "        print(\"Epoch, char acc, word acc:\", self.current_epoch, round(char_accuracy.item(), 4), round(word_accuracy.item(), 4))\n",
    "        self.log(\"val_char_acc\", char_accuracy)\n",
    "        self.log(\"val_word_acc\", word_accuracy)\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):        \n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-3)\n",
    "        '''self.scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "                                        optimizer, max_lr=3e-3,\n",
    "                                        steps_per_epoch=492,\n",
    "                                        epochs=100)\n",
    "        sched = {\n",
    "            'scheduler': self.scheduler,\n",
    "            'interval': 'step'\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": sched}'''\n",
    "                      \n",
    "        \n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"name\": \"lr-scheduler\",\n",
    "                \"scheduler\": optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.34, min_lr=1e-4, patience=15),\n",
    "                \"monitor\": \"val_word_acc\",\n",
    "                \"frequency\": 1\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        #optimizer = optim.AdamW(self.parameters(), lr=1e-3, weight_decay=1e-2)        \n",
    "        #return optimizer\n",
    "\n",
    "transcriber = LatinTranscriber(net, num_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458552b-d354-4767-aa38-072640f5fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "idx = 10\n",
    "print(torch.min(val_dataset[idx][\"image\"]), torch.max(val_dataset[idx][\"image\"]))\n",
    "plt.imshow(val_dataset[idx][\"image\"][0], cmap=\"gray\", vmin=-0.5, vmax=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c464975d-a518-41a0-9743-65f25c23015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_set_size = int(len(dataset) * 0.9)\n",
    "#valid_set_size = len(dataset) - train_set_size\n",
    "\n",
    "# split the train set into two\n",
    "#seed = torch.Generator().manual_seed(40)\n",
    "#train_set, valid_set = torch.utils.data.random_split(dataset, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "train_loader = utils.data.DataLoader(train_dataset, num_workers=4)\n",
    "valid_loader = utils.data.DataLoader(val_dataset, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8130eb9-6d8b-4db1-b6c5-78dde2781206",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329a618-87af-4d36-a7bf-0f6e2102aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(accumulate_grad_batches=1, max_epochs=100)\n",
    "trainer.fit(transcriber, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b201265-b831-49c4-86c3-ccb0254e8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), \"my_custom_best.pt\") %94% char, 82% word\n",
    "#torch.save(net.state_dict(), \"my_aguillar_repro.pt\") #91% char, 69% word\n",
    "#torch.save(net.state_dict(), \"my_all_custom_best.pt\") #88% char, 66% word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf086b6b-585b-43f3-9106-dd169657ea84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
